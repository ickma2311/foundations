{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28445578",
   "metadata": {},
   "source": [
    "# Chapter 2 Recap: Linear Algebra Essentials\n",
    "\n",
    "Use this notebook to revisit the key linear algebra concepts underpinning deep learning. Complete each prompt before checking references or solutions elsewhere."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b86c58d",
   "metadata": {},
   "source": [
    "## Study Workflow\n",
    "1. Read the question carefully and recall the underlying definitions.\n",
    "2. Work through the algebra by hand or in the scratch cells.\n",
    "3. (Optional) Verify numerically with NumPy once you have an answer.\n",
    "4. Record insights, confusions, or follow-up topics in the reflection section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ff2baf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # Optional helper for numerical checks\n",
    "\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f8dde7",
   "metadata": {},
   "source": [
    "## Part A. Basic Objects & Operations\n",
    "Scalars, vectors, matrices, and tensors form the building blocks for deep learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab7d198",
   "metadata": {},
   "source": [
    "### 1. Basic Objects\n",
    "Provide one example each of:\n",
    "- A scalar (shape `()`),\n",
    "- A vector (shape `(n,)`),\n",
    "- A matrix (shape `(m, n)`),\n",
    "- A 3rd-order tensor (shape `(d_1, d_2, d_3)`).\n",
    "\n",
    "Note the values and their shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfb8047b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(3,)\n",
      "(2, 2)\n",
      "(2, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "# TODO: define your scalar, vector, matrix, and tensor examples\n",
    "scalar = 1\n",
    "vector = np.array([1, 2, 3])\n",
    "matrix = np.array([[1, 2], [3, 4]])\n",
    "tensor3 = np.array([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n",
    "# print scalar and shapes to confirm\n",
    "print(scalar)\n",
    "print(vector.shape)\n",
    "print(matrix.shape)\n",
    "print(tensor3.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229a0002",
   "metadata": {},
   "source": [
    "### 2. Vector Operations\n",
    "Given $x = [1, 2, 3]$ and $y = [4, 5, 6]$, compute:\n",
    "1. $x + y$\n",
    "2. $2x - y$\n",
    "3. $x \\cdot y$ (dot product)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01996719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x+y= [5 7 9]\n",
      "2x-y= [-2 -1  0]\n",
      "x dot y= 32\n"
     ]
    }
   ],
   "source": [
    "x = np.array([1, 2, 3])\n",
    "y = np.array([4, 5, 6])\n",
    "\n",
    "# TODO: replace the ellipses with your computations\n",
    "# print('x + y =', ... )\n",
    "# print('2x - y =', ... )\n",
    "# print('x dot y =', ... )\n",
    "\n",
    "print('x+y=',x+y)\n",
    "print('2x-y=',2*x-y)\n",
    "print('x dot y=',x@y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa7f49e",
   "metadata": {},
   "source": [
    "### Knowledge Key Point â€” Dot Product and Angle\n",
    "\n",
    "For any non-zero vectors $\\mathbf{a}$ and $\\mathbf{b}$,\n",
    "\n",
    "$\\mathbf{a}\\cdot\\mathbf{b} = \\|\\mathbf{a}\\|\\,\\|\\mathbf{b}\\| \\cos\\theta$\n",
    "\n",
    "where $\\theta$ is the angle between them. If the vectors are perpendicular, then $\\theta = 90^\\circ$, so $\\cos\\theta = 0$ and the dot product is zero.\n",
    "\n",
    "### Exercise (TODO)\n",
    "\n",
    "Pick two non-zero vectors in $\\mathbb{R}^2$ or $\\mathbb{R}^3$ that are perpendicular. Verify numerically that their dot product is zero and that the cosine formula above also evaluates to zero.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43c8a0ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1=np.array([1,1])\n",
    "v2=np.array([-1,1])\n",
    "np.dot(v1,v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb63155",
   "metadata": {},
   "source": [
    "### 3. Matrix Operations\n",
    "For $A = \\begin{bmatrix}1 & 2 \\\\ 3 & 4\\end{bmatrix}$ and $B = \\begin{bmatrix}2 & 0 \\\\ 1 & 2\\end{bmatrix}$, determine:\n",
    "1. $A + B$\n",
    "2. $AB$\n",
    "3. $A^\\top$ (transpose)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df5489db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A + B =\n",
      " [[3 2]\n",
      " [4 6]]\n",
      "A @ B =\n",
      " [[ 4  4]\n",
      " [10  8]]\n",
      "A^T =\n",
      " [[1 3]\n",
      " [2 4]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[1, 2], [3, 4]])\n",
    "B = np.array([[2, 0], [1, 2]])\n",
    "\n",
    "# TODO: compute the requested matrix expressions\n",
    "print('A + B =\\n', A+B )\n",
    "print('A @ B =\\n', A@B )\n",
    "print('A^T =\\n', np.transpose(A) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5002c31b",
   "metadata": {},
   "source": [
    "## Part B. Matrix Properties\n",
    "Determinants and inverses reveal how linear transformations scale or distort space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f94459",
   "metadata": {},
   "source": [
    "### 4. Identity and Inverse\n",
    "1. Write the $2\\times2$ identity matrix $I$.\n",
    "2. Compute $\\det(A)$ to determine whether $A$ is invertible.\n",
    "3. If $A$ is invertible, find $A^{-1}$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c9bdcaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inverted A is: [[-2.   1. ]\n",
      " [ 1.5 -0.5]]\n"
     ]
    }
   ],
   "source": [
    "# TODO: define the identity matrix and compute determinant and inverse\n",
    "I = np.array([[1,0],[0,1]])\n",
    "det_A = 1*4-3*2\n",
    "\n",
    "if det_A != 0:\n",
    "    A_inv = np.linalg.inv(A)\n",
    "# print results for your reference\n",
    "print(\"Inverted A is:\",A_inv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1a487e",
   "metadata": {},
   "source": [
    "### 5. Determinant & Geometry\n",
    "Given $C = \\begin{bmatrix}2 & 0 \\\\ 0 & 3\\end{bmatrix}$:\n",
    "1. Compute $\\det(C)$.\n",
    "2. Explain, in your own words, the geometric meaning of a determinant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1dccd64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "det(C) = 6.0\n"
     ]
    }
   ],
   "source": [
    "C = np.array([[2, 0], [0, 3]])\n",
    "\n",
    "# TODO: compute the determinant numerically if desired\n",
    "det_C = np.linalg.det(C)\n",
    "print('det(C) =', det_C)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae03191",
   "metadata": {},
   "source": [
    "## Part C. Vector Spaces & Norms\n",
    "Norms measure vector magnitude; orthogonality and projections capture geometric relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf287fb",
   "metadata": {},
   "source": [
    "### 6. Norms\n",
    "For $x = [3, 4]$, compute:\n",
    "1. $\\lVert x \\rVert_1$\n",
    "2. $\\lVert x \\rVert_2$\n",
    "3. $\\lVert x \\rVert_\\infty$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd2bc947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.0 5.0 4.0\n"
     ]
    }
   ],
   "source": [
    "x_vec = np.array([3, 4])\n",
    "\n",
    "# TODO: compute the requested norms\n",
    "l1 = np.linalg.norm(x_vec,1)\n",
    "l2 = np.linalg.norm(x_vec,2)\n",
    "linf = np.linalg.norm(x_vec,np.inf)\n",
    "# print results here when ready\n",
    "\n",
    "print(l1,l2,linf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e31f2a6",
   "metadata": {},
   "source": [
    "### 7. Orthogonality & Projection\n",
    "With $u = [1, 0]$ and $v = [3, 4]$:\n",
    "1. Test whether $u$ and $v$ are orthogonal.\n",
    "2. Compute the projection of $v$ onto $u$.\n",
    "Projection Formula:\n",
    "$$\n",
    "proj_{v}(u)=\\frac{u\\cdot v}{u\\cdot u}u\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74d50353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 [3. 0.]\n"
     ]
    }
   ],
   "source": [
    "u = np.array([1, 0])\n",
    "v = np.array([3, 4])\n",
    "\n",
    "# TODO: compute u dot v and the projection expression\n",
    "dot_uv = u@v\n",
    "\n",
    "proj_v_on_u = ((u@v)/(u@u))*u\n",
    "# print your conclusions\n",
    "print(dot_uv,proj_v_on_u)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba219e8",
   "metadata": {},
   "source": [
    "## Part D. Eigenvalues & Eigenvectors\n",
    "Eigen decompositions help interpret linear transformations and power techniques like PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a542591a",
   "metadata": {},
   "source": [
    "### 8. Eigenvalues & Eigenvectors\n",
    "For $A = \\begin{bmatrix}2 & 0 \\\\ 0 & 3\\end{bmatrix}$:\n",
    "1. Find its eigenvalues.\n",
    "2. For each eigenvalue, record one corresponding eigenvector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02415b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 3.]\n",
      "[[1. 0.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "A_diag = np.array([[2, 0], [0, 3]])\n",
    "\n",
    "# TODO: compute eigenvalues and eigenvectors manually or with numpy.linalg.eig\n",
    "eigvals, eigvecs = np.linalg.eig(A_diag)\n",
    "print(eigvals)\n",
    "print(eigvecs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2d010d",
   "metadata": {},
   "source": [
    "### 9. Diagonalization\n",
    "State whether the above matrix $A$ is diagonalizable and provide your reasoning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea00e46",
   "metadata": {},
   "source": [
    "## Part E. Applications in Deep Learning\n",
    "Connect linear algebra back to neural network computations and dimensionality reduction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc6ed14",
   "metadata": {},
   "source": [
    "### 10. Neural Network Layer\n",
    "For input $x = [1, 2]$, weights $W = \\begin{bmatrix}1 & -1 \\\\ 0 & 2\\end{bmatrix}$, and bias $b = \\begin{bmatrix}1 \\\\ 0\\end{bmatrix}$, compute the layer output $y = Wx + b$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f74c7078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer output y = [0 4]\n"
     ]
    }
   ],
   "source": [
    "x_input = np.array([1, 2])\n",
    "W = np.array([[1, -1], [0, 2]])\n",
    "b = np.array([1, 0])\n",
    "\n",
    "# TODO: compute y\n",
    "y = np.dot(W,x_input.transpose())+b\n",
    "print('Layer output y =', y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9106993f",
   "metadata": {},
   "source": [
    "### 11. PCA Connection\n",
    "Explain why eigenvalue decomposition is useful for dimensionality reduction techniques such as PCA. Provide an intuitive explanation in your own words.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babccd07",
   "metadata": {},
   "source": [
    "## Reflection\n",
    "Summarize the areas that felt most comfortable or challenging, and list any follow-up resources to consult.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
