{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“˜ Probability and Information Theory â€” Knowledge Points and Exercises\n",
    "\n",
    "Use this chapter to review core probability tools that appear throughout modern deep learning. Concepts are paired with exercises so you can implement the ideas in code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Probability Basics\n",
    "\n",
    "- Random variables: discrete vs. continuous\n",
    "- Probability distributions:\n",
    "  - Probability Mass Function (PMF)\n",
    "  - Probability Density Function (PDF)\n",
    "- Key rules:\n",
    "  - Joint probability $P(X, Y)$\n",
    "  - Marginal probability $P(X)$\n",
    "  - Conditional probability $P(X\\mid Y)$\n",
    "  - Independence and conditional independence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Common Distributions\n",
    "\n",
    "- **Bernoulli**: binary outcomes\n",
    "- **Binomial**: number of successes in fixed trials\n",
    "- **Multinomial**: multi-class outcomes\n",
    "- **Gaussian (Normal)**: continuous, bell-shaped\n",
    "- **Poisson** and **Exponential**: rare events, waiting times\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bfd6f5",
   "metadata": {},
   "source": [
    "## 3. Expectation and Variance\n",
    "\n",
    "- **Expectation** (mean): average value of a random variable  \n",
    "  $\\displaystyle \\mathbb{E}[X] = \\sum_x x P(x)$ (discrete),  \n",
    "  $\\displaystyle \\mathbb{E}[X] = \\int x p(x)\\,dx$ (continuous)\n",
    "- **Variance**: measure of spread around the mean  \n",
    "  $\\displaystyle \\text{Var}(X) = \\mathbb{E}[(X - \\mathbb{E}[X])^2]$\n",
    "- **Covariance and correlation**: measure linear relationships between two variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Bayes' Theorem\n",
    "\n",
    "$\\displaystyle P(A\\mid B) = \\frac{P(B\\mid A)P(A)}{P(B)}$\n",
    "\n",
    "- Updates belief about event $A$ given evidence $B$\n",
    "- Foundation of Bayesian inference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Information Theory\n",
    "\n",
    "- Information content: $I(x) = -\\log P(x)$\n",
    "- Entropy: $H(X) = -\\sum_x P(x)\\log P(x)$\n",
    "- Conditional entropy: $H(X\\mid Y)$\n",
    "- Cross-entropy: $H(P, Q) = -\\sum_x P(x)\\log Q(x)$\n",
    "- KL divergence: $D_{KL}(P\\Vert Q) = \\sum_x P(x) \\log \\frac{P(x)}{Q(x)}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Applications in Machine Learning\n",
    "\n",
    "- Maximum Likelihood Estimation (MLE)\n",
    "- Bayesian inference\n",
    "- Loss functions based on information theory:\n",
    "  - Cross-entropy loss\n",
    "  - KL divergence (e.g., in variational inference)\n",
    "- Probabilistic modeling of uncertainty\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Exercises\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Probability Basics\n",
    "A fair coin is flipped twice.\n",
    "1. List the sample space.\n",
    "2. Compute $P(\\text{at least one head})$.\n",
    "3. Compute $P(\\text{first flip is tail} \\mid \\text{total heads} = 1)$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement Exercise 1 calculations\n",
    "print(\"The sample space is:HH HT TH TT \")\n",
    "print(\"P(at least one head):\",1-0.25)\n",
    "print(\"P(first flip is tail | total heads = 1):\",0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Gaussian Distribution\n",
    "Let $X \\sim \\mathcal{N}(0, 1)$.\n",
    "1. What is $P(X \\leq 0)$?\n",
    "2. Compute the expectation $\\mathbb{E}[X]$.\n",
    "3. Compute the variance $Var(X)$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement Exercise 2 calculations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Bayes' Theorem\n",
    "A disease affects 1% of a population.\n",
    "- Test sensitivity: 99%\n",
    "- False positive rate: 5%\n",
    "\n",
    "If a patient tests positive:\n",
    "1. Compute $P(\\text{disease} \\mid \\text{positive})$.\n",
    "2. Interpret the result.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement Exercise 3 calculations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Entropy\n",
    "A random variable $X$ has distribution: $P(X=0)=0.25$, $P(X=1)=0.25$, $P(X=2)=0.5$.\n",
    "1. Compute entropy $H(X)$.\n",
    "2. Which outcome contributes most to entropy?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement Exercise 4 calculations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: Cross-Entropy and KL Divergence\n",
    "True distribution $P = (0.7, 0.3)$.\n",
    "Predicted distribution $Q = (0.6, 0.4)$.\n",
    "1. Compute cross-entropy $H(P, Q)$.\n",
    "2. Compute KL divergence $D_{KL}(P\\Vert Q)$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement Exercise 5 calculations\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
